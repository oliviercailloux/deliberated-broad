= Préférences argumentées et liens avec autres disciplines
:toc:

== Résumé
Un objectif important de la science est de contribuer à notre capacité à prendre de bonnes décisions. Mais les approches normatives actuelles requièrent une définition de la rationalité a priori. Les façons de définir ce qu’est une bonne décision sont multiples et n’ont pas pu à ce jour réunir de consensus. Les approches descriptives, elles, se contentent d’étudier le comportement normal d’un décideur, et non de l’aider à prendre une bonne décision. Ce projet de recherche introduit une nouvelle perspective concernant l’aide à la décision. Il propose d’étudier ce que les humains considèrent comme des arguments pertinents. La proposition s’appuie sur les idées de plusieurs champs : la théorie de la décision (et particulièrement l’approche constructive), l’épistémologie, la philosophie politique, et propose de s’inspirer des techniques développées en théorie de l’argumentation pour développer un cadre formel permettant la comparaison de méthodes d’aide à la décision. Ceci permet d’aborder la question de manière empirique et de trancher les débats entre approches concurrentes. Inversement, les champs disciplinaires cités pourront bénéficier des découvertes engendrées par la perspective proposée.

Mots clés : 

* théorie de la décision ;
* épistémologie du désaccord ;
* psychologie cognitive ;
* théorie de l’argumentation ;
* choix social.

== Introduction

Un objectif important de la science est de contribuer à notre capacité à prendre de bonnes décisions. De plus, lorsque la décision à prendre a un impact sur la société, il est nécessaire que la décision soit perçue comme bonne par les citoyens, pas seulement par les décideurs. Ainsi, pour paraphraser la règle bien connue du droit anglo-saxon, la tâche qui nous incombe n’est pas seulement d’aider à prendre de bonnes décisions : il faut également aider à prendre des décisions dont on peut voir qu’elles sont bonnes.

Ce projet de recherche propose une nouvelle perspective concernant l’aide à la décision, en s’appuyant sur une définition simple de ce qui rend une décision bonne, aux yeux d’une personne donnée. L’idée défendue dans ce projet est qu’il est nécessaire de développer une compréhension de ce que les humains considèrent comme des arguments pertinents. En effet, ce sont ultimement les arguments qui nous permettent d’évaluer une décision comme bonne ou mauvaise. Cette vision permet d’aborder la question de manière empirique. En nous appuyant sur les connaissances ainsi générées de ce qui rend un argument bon aux yeux des humains, nous pourrons, dans un second temps seulement, définir la rationalité de façon consensuelle.

Pour ce projet de recherche, une bonne décision est une décision en faveur de laquelle il peut être donné des arguments qui résistent aux contre-arguments, ainsi qu’évalué par le décideur lui-même. L’objectif est d’étudier ce qu’un humain considère comme un argument pertinent, éventuellement en fonction des circonstances, de leur formulation, ou d’autres paramètres à découvrir. Il s’agit d’étudier ce que j’appellerai ici des préférences argumentées (appelées préférences réfléchies dans la proposition initiale suggérée dans ma thèse de doctorat (Cailloux, 2012)).

La proposition s’appuie sur les idées de plusieurs champs : la théorie de la décision et en particulier l’approche constructive de l’AMCD, l’épistémologie, la philosophie politique, et propose de s’inspirer des techniques développées récemment en théorie de l’argumentation pour développer un cadre formel permettant la comparaison de méthodes d’aide à la décision, évaluant leur capacité à aider le décideur à atteindre une bonne décision, à la lumière de la définition proposée. Inversement, les champs disciplinaires cités pourront bénéficier également des découvertes engendrées par la perspective proposée, comme explicité ci-dessous.

Pour ce faire, il nous faudra développer des systèmes qui aident à décider en produisant des arguments que le décideur trouve pertinents. Je propose une manière de faire cela en évitant le recours à des hypothèses fortes sur les capacités de raisonnement des décideurs. Par exemple, il ne sera pas nécessaire de considérer le décideur comme un être toujours rationnel au sens entendu par les économistes. De plus, la vision avancée permettra une comparaison et une validation des modèles proposés, permettant de trancher les débats entre approches concurrentes.

La section suivante présente cette proposition. Les différents champs d’investigation liés sont détaillés ensuite, avec pour chaque approche, ce qui la distingue de la proposition développée ici, et ce qui l’y lie. Ces deux sections parlent principalement d’une situation d’aide à la décision d’un décideur unique. Ensuite, la discussion est étendue à l’aide à la décision de décideurs multiples. Finalement, la façon envisagée de mener ce projet de recherche est présentée par le biais de deux applications. Ces deux applications, en plus d’être intéressantes en soi, fourniront des objectifs concrets à poursuivre à court, moyen et long terme et permettront donc de développer le projet concrètement.

== L’étude des préférences argumentées

Dans cette proposition, l’étude de la pertinence des arguments ainsi qu’évaluée par les humains passe par le développement de modèles de préférences argumentées, et par le développement d’un cadre permettant de comparer, valider et falsifier les modèles de préférences argumentées. Définissons donc d’abord ce concept.

Un modèle de préférences argumentées prend une série de positions sur la façon dont un décideur accepte les arguments. Soit une décision à prendre concernant un sujet donné. Un modèle de préférences argumentées prétend, pour ce sujet, qu’un certain ensemble de points de vue concernant ce sujet seront considérés comme valables par le décideur après réflexion. Le modèle fournit également, étant donné un sujet, des arguments en faveur de ces points de vue qu’il prétend valables. Enfin, il fournit des contre-arguments aux arguments émis contre les points de vue défendus par le modèle, et des contre-arguments aux arguments en faveur des points de vue rejetés par le modèle.

On peut imaginer plusieurs façons de formaliser un modèle de préférences argumentées à partir de cette description générale. Une partie de la recherche à mener consistera à déterminer quelles sont les instanciations formelles les plus pertinentes. Voici une manière possible de concevoir un modèle de préférences argumentées. Le modèle définit un ensemble d’arguments, entendus comme de simples textes exprimés dans un langage naturel compris par le décideur. Il contient également un ensemble de points de vues, eux aussi des textes en langage naturel, qu’il considère comme valables pour ce problème de décision. Ces « points de vues » peuvent consister en des affirmations telles que : telle alternative est la meilleure, elle devrait être choisie, ou : tel critère est crucial et devrait déterminer à lui seul vos préférences, ou encore : telle opinion est valide étant donné les preuves en présence. Enfin, le modèle contient deux fonctions qui fournissent des arguments. D’une part, lorsqu’on lui demande un argument en faveur d’une des options qu’il défend, le modèle fournit un argument. D’autre part, lorsqu’on fournit un contre-argument à un de ses arguments, le modèle fournit un contre-contre-argument. Cette même fonction est également utilisée par le modèle pour tenter de contrer les arguments contre ses contre-contre-arguments, et ainsi de suite.

Voyons maintenant comment valider et comparer des modèles de préférences argumentées.

Un modèle de préférences argumentées est d’autant meilleur que les points de vue qu’il défend sont ultimement acceptés comme valables par le décideur, et que les points de vue rejetés par le modèle sont finalement considérés comme non valables par le décideur, étant donné l’argumentation fournie par le modèle. Deux manières de tester le modèle au moins peuvent être envisagées : faire jouer le modèle contre le décideur (test modèle contre humain), ou faire jouer le modèle contre un autre modèle (test modèle contre modèle). La source des contre-arguments est, dans le premier cas, le décideur, dans le deuxième, le modèle concurrent. Dans les deux cas, le décideur arbitre.

Dans le test modèle contre humain, le décideur prend connaissance des points de vue défendus par le modèle. Le décideur peut choisir un point de vue et demander au modèle un argument en faveur de ce point de vue. Il peut soit déclarer que cet argument est convaincant et que le point de vue est valide, s’il ne voit pas d’objections à ce raisonnement (menant à une victoire du modèle pour cet aspect), soit fournir un contre-argument au modèle. Le modèle doit dans ce cas fournir un contre-argument au contre-argument, sous peine d’être défait pour cet aspect. Le contre-contre-argument sera à son tour soumis pour évaluation au décideur, qui peut à nouveau fournir un contre-argument, et ainsi de suite. Pour les sujets de décision suffisamment importants, le modèle sera sans-doute trop grand pour être testé entièrement, mais, comme pour les modèles physiques, les tests de falsifiabilité ne doivent pas nécessairement être conduits de façon exhaustive contre toutes les prédictions du modèle.

Le test modèle contre modèle est nécessaire car un humain ne peut être considéré comme ayant en tête tous les arguments pertinents concernant un problème de décision. Il est en effet possible qu’un modèle passe le test contre l’humain alors qu’il donnerait des conseils peu avisés, mais bons en apparence. Après publication d’un modèle donné, une équipe de recherche éventuellement différente peut proposer un système de modélisation dont elle prétend qu’il produit des modèles de préférences argumentées qui sont de meilleur conseil. Pour le vérifier, les modèles concurrents peuvent chacun argumenter en faveur des points de vue qu’ils défendent respectivement. Le décideur indiquera quels arguments lui semblent pertinents et résistants aux contre-arguments.

Il sera ici aussi nécessaire de préciser comment déterminer que le décideur accepte un argument. Une  manière de tester la pertinence d’un argument consiste à demander au décideur, lorsque le modèle prétend qu’un argument soutient un point de vue : cet argument, en supposant qu’il soit correct, soutient-il effectivement ce point de vue ? Il faut aussi demander au décideur, pour chaque contre-contre-argument fourni par le modèle : l’argument fourni, en supposant qu’il ne soit pas lui-même contré, contre-t-il effectivement l’argument qu’il prétend contrer ?

Un inconvénient de l’instanciation proposée ci-dessus, considérant les arguments sous la simple forme de textes, est qu’il sera généralement difficile de proposer des modèles capables de contre-argumenter. Le domaine d’application d’une telle conception se limitera vraisemblablement à des domaines précis où l’ensemble des contre-arguments qui peuvent être invoqués par des humains ou des modèles concurrents n’est pas trop grand. Pour contourner cette difficulté, un modèle pourrait argumenter en utilisant un langage plus restreint que le langage naturel.

Il reste à indiquer comment prendre en compte la subjectivité du décideur, c’est-à-dire dans ce cadre, la possible propension qu’ont des individus distincts à accepter des arguments différents, ou présentés différemment. Pour ce faire, une équipe de chercheurs proposera non pas un modèle de préférences argumentées, mais un système de modélisation, équivalent d’une classe de modèles dans le cadre AMCD standard. Le système doit être accompagné d’une procédure indiquant comment le paramétrer en fonction de la situation de décision et du décideur, par exemple, en posant des questions au décideur. Une fois paramétré, le système définirait un modèle de préférences argumentées dont il prétend qu’il représente ce décideur dans cette situation. Un système de modélisation de préférences argumentées sera jugé d’autant meilleur qu’il a tendance à produire des modèles de préférences argumentées valides en posant peu de questions au décideur.

Notons que le terme « préférences » est utilisé ici de façon très large, puisque le cadre permet également d’étudier les opinions d’individus dans une situation déconnectée de problèmes de décision : l’opinion que l’individu adopte finalement (celle qu’il « préfère ») étant donné les arguments fournis et ceux qu’il a en tête. Le terme décideur désigne dans un tel cas l’individu qui doit décider de l’opinion à adopter, plutôt que décider d’une action.

Notons également que le cadre défini ici ne requiert pas un problème de décision bien défini, structuré à l’aide d’un système de critères cohérents par exemple. Il se prête donc parfaitement à l’intégration de méthodes de génération de points de vues originaux ou de nouvelles alternatives (Mingers & Rosenhead, 2001; Franco et al., 2010).

Mon projet de recherche consiste, d’une part, à développer le cadre formel de définition et de comparaison des modèles de préférences argumentées en suscitant un débat inter-domaine, et d’autre part à développer les modèles de préférences argumentées eux-mêmes. La section suivante indique quels champs alimenteront et seront intéressés par cette discussion et montre en quoi ce projet se distingue des approches proposées par chaque discipline.

== Liens avec les champs existants

=== Théorie de la décision et psychologie

Une méthode d’aide à la décision prenant en compte la subjectivité d’un décideur obtient un modèle de préférence de ce décideur concernant le problème auquel il fait face, et appuie ses recommandations sur ce modèle. Pour ce faire, une telle méthode doit définir une classe de modèles parmi laquelle chercher un modèle adéquat, puis définir une façon de préciser quel modèle s’applique. (Cf. section 3.1.)

Afin d’assurer une forte légitimité aux recommandations issues d’un processus d’aide à la décision, il faut éviter les choix arbitraires : il faut une manière unique, consensuelle, de définir la « bonne » classe de méthodes parmi laquelle chercher un modèle de préférence, et la bonne manière d’éliciter les préférences. (Excepté si l’on peut montrer que les autres manières raisonnables de procéder aboutissent aux mêmes conclusions, mais nous verrons que ce n’est pas le cas.) C’est le programme proposé par la théorie de la décision classique. Des systèmes d’axiomes cohérents et attractifs ont été proposés pour définir la classe de modèles à laquelle s’intéresser, sur lesquels les méthodes d’aide à la décision les plus étudiées actuellement ont été bâties : la théorie de l’utilité pour les décisions dans le risque (von Neumann & Morgenstern, 2007), la théorie de la valeur multi-attribut (MAVT) pour les problèmes multicritères (Keeney & Raiffa, 1993), et leurs variantes (Dyer, 2005).

Cependant, ces axiomes ont été critiqués, d’une part (Ellsberg, 1961; Fellner, 1961; Allais, 1979), et d’autre part des chercheurs ont proposé d’autres systèmes d’axiomes également attractifs (Bouyssou & Pirlot, 2002; Bouyssou, Dubois, Pirlot, & Prade, 2006; Galaabaatar & Karni, 2013).

Par ailleurs, une fois la classe de modèles choisie, il convient de déterminer les paramètres de préférence du décideur en lui posant des questions. De nombreuses études en psychologie ont montré que différentes manières de poser une question suscitent des réponses différentes (Tversky, Sattath, & Slovic, 1988; Lichtenstein & Slovic, 2006). Il ne semble pas y avoir de moyen simple de déterminer quelle façon de poser la question est la bonne. Les psychologues ont également révélé l’existence de deux modes de raisonnements, que Kahneman (2013) appelle pensée rapide et pensée lente, le premier intuitif, le deuxième faisant appel à des raisonnements plus complexes et conscients.

Les travaux des psychologues soulèvent une question importante. Si l’on constate des différences entre les réponses intuitives aux questions de préférences et les réponses qui seraient données en suivant une approche normative donnée, convient-il d’affirmer que le sujet exprimant ses préférences est dans l’erreur ? Répondre d’emblée par l’affirmative semble dangereux, car cela donnerait un grand pouvoir aux intellectuels développant les modèles sur les sujets (assujettis) exprimant leurs préférences.

Une façon d’éclairer cette question, proposée ici, serait d’étudier dans quelle mesure le sujet est prêt à réviser sa position lorsque des arguments en faveur de l’approche normative proposée lui sont présentés. Cette question est très peu étudiée à l’heure actuelle, ce qui peut être dû à l’absence de cadre formel pour explorer ce genre d’interrogations. De rares études ont exploré la possibilité de faire changer un sujet d’avis en lui présentant un argument donné (Slovic & Tversky, 1974), mais il n’y a pas eu d’étude systématique de la force de divers arguments ou d’argumentations non triviales composées d’arguments et de contre-arguments.

Alors que la théorie de la décision classique voit les préférences comme un objet déterminé que la méthode d’aide à la décision doit découvrir, l’approche constructive propose de considérer les préférences comme construites au cours du processus d’aide à la décision (cf. section 3.4). Ainsi, les chercheurs s’inscrivant dans ce courant sont intéressés par l’étude de classes de modèles différents et ne pensent pas que l’un d’entre eux puisse être définitivement considéré comme meilleur que les autres. Ils proposent de choisir la classe de modèles en fonction du problème et de la façon dont le décideur raisonne. Mais ce problème est probablement aussi difficile à résoudre que le problème de décision de départ. Des méthodes formelles n’ont pas été proposées pour aider à ce choix, puisque tenter de faire ceci poserait un problème de régression à l’infini. L’absence de consensus sur la méthode à adopter laisse intacte la question de la légitimité des recommandations.

Les modèles classiques de la théorie de la décision ont été critiqués pour une autre raison (Aumann, 1962; Roy, 1985; Sen, 1997) : ils postulent la comparabilité entière. Ils supposent que l’on peut toujours aboutir, au terme de la procédure d’aide à la décision, à un modèle de préférence permettant de comparer toutes les alternatives en présence et d’indiquer pour chaque paire d’entre elles laquelle le décideur préfère, ou s’il les considère comme également bonnes. Au contraire, l’approche constructive laisse ouverte la possibilité que le modèle issu du processus d’aide à la décision comprenne des zones d’incomparabilité : des paires d’alternatives dont il ne peut être déterminé laquelle est meilleure ou si elles sont ex-æquo. Ceci se produit typiquement pour des paires d’alternatives aux performances très contrastées, très bonnes selon certains aspects et très mauvaises selon d’autres (Deparis, Mousseau, Öztürk, Pallier, & Huron, 2012). D’importants débats ont eu lieu entre ceux qui pensent que l’aide à la décision peut et doit aboutir à une seule vision des choses permettant des recommandations non ambiguës et ceux qui pensent qu’il n’est pas nécessairement possible d’obtenir un tel résultat de façon valide (Schärlig, 1996; Zionts, 1997; Roy & Vincke, 1998; Marchant & Pirlot, 1999). Ces débats n’ont jamais pu être tranchés, tout comme de manière plus générale la question du choix des méthodes, en raison à mon avis de l’absence de cadre pour comparer les méthodes et approches d’aide à la décision.

Mon projet propose d’éclairer précisément cette importante question : quels raisonnements le décideur trouve-t-il convaincants ?

L’approche proposée dans ce projet de recherche permet de passer outre les difficultés mentionnées ici. Les modèles de préférences argumentées peuvent effectivement être validés, contre le décideur et entre eux. Le décideur lui-même, plutôt qu’un chercheur, détermine quelle approche lui semble pertinente. Formuler les arguments de différentes façons peut amener le décideur à voir le problème de différentes façons. Mon approche ne requiert pas de postuler la comparabilité entière. En effet, rien n’empêche de permettre dans le cadre général à un modèle de préférences argumentées de fournir des arguments pour deux points de vue contradictoires, si l’on pense que le décideur est prêt à considérer les deux points de vue comme intéressants. Ainsi, un argument pourrait défendre le point de vue qu’une alternative est meilleure qu’une autre (par exemple, parce qu’elle est si bonne sur certains critères), un autre pourrait défendre le point de vue inverse. La question de savoir s’il est pertinent d’autoriser cette forme d’incomparabilité devient alors une question de fait, qui peut être explorée par le biais de la comparaison de modèles issus d’équipes de recherche ayant des intuitions différentes à ce sujet.

L’étude des préférences argumentées proposée ici devra se nourrir des observations des psychologues pour comprendre et anticiper les arguments que des décideurs pourraient formuler en faveur d’une alternative favorisée par leur pensée rapide, et proposer des contre-arguments adéquats. Inversement, observer, grâce à l’étude de modèles de préférences argumentées, quels arguments sont jugés pertinents pour contrer les raisonnements de pensée rapide constituera un apport intéressant la psychologie. De façon similaire, on peut soupçonner que certains raisonnements dictés par la pensée rapide seront en fait considérés comme corrects par un certain nombre de décideurs même après réflexion. Que cela se produise ou non, ces résultats nourriront indubitablement les réflexions des psychologues.

Les modèles existants, issus de la théorie de la décision classique ou pas, sont basés sur des intuitions claires et sont souvent entièrement formalisés grâce aux systèmes d’axiomes concernant la façon dont les humains souhaitent, ou devraient souhaiter, raisonner. Ces mêmes éléments constitueront la base indispensable de l’approche proposée ici, puisqu’un modèle de préférences argumentées doit être capable de déterminer quels arguments le décideur trouvera pertinents. Pour développer ces modèles de préférences argumentées, un développement mathématique des intuitions sous-tendant la génération des arguments par le modèle sera utile. Inversement, le développement de modèles de préférences argumentées pourra alimenter la recherche en d’autres modèles de décision classique.

=== Épistémologie

Le champ de l’épistémologie étudie les conditions de production de savoir valide. Une de ses branches, l’épistémologie du désaccord (Feldman, 2010; Christensen & Lackey, 2013), s’intéresse aux possibilités et conditions de désaccords persistants entre humains. Partant de la constatation que des gens visiblement raisonnables et intelligents peuvent avoir des positions tranchées, divergentes et stables sur des questions importantes, les philosophes s’interrogent sur l’attitude qu’il convient d’adopter lorsqu’on se trouve en désaccord avec un « pair épistémique » : une personne qui possèdent les mêmes accès aux faits et aux arguments concernant une question donnée, et des capacités de raisonnement similaires.

La question se pose de l’opportunité de réviser ses propres croyances lors de la découverte de pairs épistémiques ayant des opinions contraires aux siennes. Le débat oppose, entre autres, la position « conciliationiste », proposant de rejoindre son opposant en modérant sa propre position, et la position de la « ligne dure » (hard line, ou stick to your guns) affirmant qu’il peut être raisonnable de conserver sa propre position malgré l’existence de pairs épistémiques en désaccord. Lié à ce débat, le principe d’unicité postule l’existence, pour toute question, d’une position doxastique unique maximalement rationnelle. Il affirme, autrement dit, qu’il existe toujours une seule façon pleinement rationnelle d’orienter ses opinions (beliefs) face à un ensemble de faits et d’arguments donné. Ce principe a été défini de plusieurs manières et fait l’objet de controverses dans la littérature (White, 2005; Feldman, 2007; Kelly, 2010). J’utilise dans la suite de cette section le seul terme « argument » pour désigner tout élément pouvant être utilisé à l’appui d’une position doxastique. Les philosophes utilisent plus volontiers le concept de preuve (proof), qui est plus spécifique (Williamson, 2008, Chapitre 7), mais je néglige cette différence dans cette discussion.

Le cadre proposé ici permet d’étudier certaines de ces questions de façon empirique, et ainsi contribuer au débat philosophique. Les concepts utilisés dans le débat peuvent être définis précisément dans ce cadre et on peut alors en étudier précisément la version ainsi définie. Inversement, étudier les questions posées et les arguments avancés par les philosophes permettra de développer plus avant le cadre de comparaison de modèles de préférences argumentées et les modèles eux-mêmes. Il est vrai toutefois que les positions de principes concernant ce que devrait être la bonne manière de raisonner ne sont pas ultimement contraintes par la façon dont les gens raisonnent effectivement. Mais l’étude de cette question de manière empirique contribuera à éclairer le débat. Quelques exemples de sujets d’interaction potentiellement fructueuse entre ma proposition et le champ de l’épistémologie du désaccord suivent.

Il est possible de contribuer à étudier les conditions d’existence de pairs épistémiques en désaccord en modélisant l’opinion de différentes personnes face à un sujet controversé donné. Le cadre offre une manière formelle de s’assurer que les personnes testées utilisent effectivement les mêmes arguments, et permettra éventuellement de découvrir des situations où deux personnes différentes peuvent être représentées de façon adéquate par des modèles de préférences argumentées utilisant le même ensemble d’arguments mais aboutissant à des conclusions différentes. Cette approche permet d’étudier dans quelle mesure des personnes peuvent trouver pertinent un argument alors même qu’il ne convainc pas une autre personne. Ceci est lié à la conception dialectique des preuves (Williamson, 2008, Chapitre 7). Cette conception suggère qu’un argument ne devrait être considéré comme valable que s’il convainc autrui. Le cadre permet de voir dans quelle mesure ceci est considéré comme naturel par les sujets testés. Un modèle de préférences argumentées peut même faire appel à des arguments indiquant à la personne testée que tel argument (qu’elle trouve a priori convaincant) n’a pas convaincu telle série d’autres personnes, afin de tester dans quelle mesure la conviction d’un individu peut être ébranlée par la connaissance de l’existence de désaccords parmi des pairs.

Cette question est à son tour liée à la mesure dans laquelle un individu a tendance à s’accrocher à son opinion initiale sur un sujet donné, même face à d’autres arguments. Les psychologues ont montré qu’une telle tendance existe (Gilbert, 2006, p. 180 – 187) : des individus face à des textes argumentant en faveur de thèses opposées prêtent souvent plus d’attention aux textes et jugent de façon plus favorable les arguments en faveur de la thèse à laquelle ils adhéraient avant de prendre connaissance des arguments. Mais le cadre proposé ici permet d’explorer cette question plus profondément par l’intermédiaire des modèles de préférences argumentées, qui permettent l’étude précise de la force de chaque argument entouré de ses contre-arguments.

Feldman (2007) s’intéresse aux conditions d’existence d’un désaccord rationnel : deux individus peuvent-ils être en désaccord durable sur une question tout en admettant que l’autre est également rationnel ? Il considère que si deux options sont considérées comme également bien argumentées par un individu, alors sa seule attitude raisonnable est de suspendre son jugement. Il s’ensuit, dit-il, qu’un désaccord entre pairs épistémiques est incompatible avec l’hypothèse que les deux individus soient également rationnels. Néanmoins, il souligne la différence entre les raisons d’adopter une opinion donnée et les raisons d’agir. Feldman fait remarquer que face à un embranchement, sans argument pertinent permettant de savoir lequel des deux chemins il convient d’emprunter pour arriver à destination, l’attitude rationnelle consiste à suspendre son jugement, mais à emprunter néanmoins un des deux chemins.

Il serait intéressant d’étudier dans quelle mesure un individu peut suspendre son jugement, ce qui peut être compris dans notre cadre comme déclarer deux points de vue contradictoires comme également valables car tous deux soutenus de manière valide par l’argumentation proposée par le modèle de préférences argumentées. De plus, comme indiqué à la section 4.1, le cadre proposé ici permet de tester de manière unifiée des opinions pures et des préférences concernant des actes. Nous pouvons alors observer dans quelle mesure un individu qui déclare deux raisonnements comme également valables est effectivement prêt, s’il est placé dans une situation de décision, à adopter indifféremment l’une ou l’autre action indiquée comme préférée par chaque raisonnement. On peut penser au contraire qu’un individu pourrait préférer, sans pouvoir le justifier, une action à une autre, alors que du point de vue argumentatif pur il les déclarerait comme toutes deux des choix rationnels.

Une autre discussion concerne les arguments « épistémiquement privés ». Dans certains cas, les désaccords peuvent se résoudre car chacun peut expliquer à autrui son mode de raisonnement en détail, jusqu’à ce que la différence et l’erreur éventuelle d’un protagoniste apparaisse. L’exemple typique est celui de deux personnes qui parviennent à deux résultats différents lors d’un calcul mental (Christensen, 2009). Dans d’autres cas cependant, certains « arguments » sont des sensations qui ne peuvent être communiqués. Christensen (2007) donne l’exemple de personnes avec une faculté spéciale leur permettant de « voir » le résultat de calculs complexes sans pouvoir expliquer l’algorithme qu’ils suivent. Kelly (2010) donne l’exemple de deux personnes qui pensent chacune avoir vu un cheval différent gagner la course à laquelle elles assistent. Rosen (2001) considère qu’on peut refuser de considérer une argumentation comme convaincante sans pouvoir pour autant la réfuter car elle fait appel à de la cruauté, sentiment qu’un protagoniste peut considérer comme négatif sans pouvoir expliquer pourquoi. Un raisonnement similaire pourrait s’appliquer à un exemple proposé par Christensen (2007) qui considère deux médecins imaginaires en désaccord sur la validité d’une théorie : l’un préfère celle qui est plus simple, l’autre celle qui semble mieux corroborée par les faits. Notons qu’on s’approche ici fortement du cas typique où une incomparabilité peut survenir dans une approche d’aide à la décision multicritère. Chacune de ces situations fournit des exemples qui peuvent être testés dans le cadre proposé ici. On peut l’utiliser pour étudier dans quelle mesure les désaccords persistants peuvent être catégorisés. Pour chacune de ces catégories, les questions vues ci-dessus se posent : les individus maintiennent-ils leur position s’ils apprennent que d’autres raisonnent différemment d’eux ; est-il possible de leur faire abandonner leur position initiale à l’aide d’arguments bien choisis ; sont-ils prêts à suspendre leur jugement dans une situation d’argumentation théorique et à adopter en conséquence une attitude indifférente concernant le raisonnement pratique ?

Enfin, la philosophie s’intéresse à des problèmes tels que le problème de Newcomb (Nozick, 1969) mettant en scène différents modes de raisonnement, tous apparemment censés et menant à des conclusions différentes. De tels problèmes sont particulièrement intéressants dans notre cadre, puisque nous pourrions tester différentes manières de présenter les arguments en faveur d’une réponse ou d’une autre et mesurer l’éventuelle variabilité inter-individuelle dans le jugement de la pertinence des arguments. Les philosophes étudiant de tels problèmes pourront nous éclairer concernant les manières intéressantes de présenter les arguments, et seront certainement intéressés par les résultats de ces investigations.

=== Théorie de l’argumentation

Pollock (1986, 2006) a proposé une théorie de la rationalité : une façon dont des humains devraient selon lui raisonner, par le biais principalement de la manipulation d’arguments. Grâce à ce travail et celui de ses successeurs, des connaissances importantes disponibles dans le champ de la rhétorique et plus généralement de la philosophie ont été rendues accessibles en intelligence artificielle. Dung (1995) a proposé un cadre formel très général permettant d’évaluer des arguments et de déterminer ceux qui sont cohérents.

Le cadre général proposé par Dung peut servir de point de départ dans l’approche proposée ici comme base de raisonnement de modèles possibles de préférences argumentées.

Une observation importante de la théorie de l’argumentation est que le raisonnement humain est non monotone, contrairement à la déduction en logique classique. Cela signifie qu’un humain obtient des conclusions temporaires, qu’il considère valide en l’absence de contre-arguments (« jusqu’à preuve du contraire », dit l’expression française). Le système proposé ici s’appuie sur cette observation et sur le cadre formel proposé par Dung en considérant les arguments comme étant non nécessairement décisifs : un modèle de préférences argumentées doit être prêt à avancer les contre-arguments adéquats aux réfutations de ses affirmations.

Une différence cruciale entre ma proposition et l’approche de la théorie de l’argumentation est que je m’intéresse à l’étude empirique de ce qui rend un argument acceptable, aux yeux d’un humain. La théorie de l’argumentation, au contraire, considère des situations où la relation entre les arguments, encodée par la relation dite d’« attaque » entre arguments, est connue et consensuelle. Par exemple, elle peut être calculée à partir des représentations logiques des arguments (Besnard & Hunter, 2009), ou donnée a priori (Baroni & Giacomin, 2009).

Certains auteurs (Amgoud & Prade, 2009; Bench-Capon & Atkinson, 2009; Ouerdane, Maudet, & Tsoukiàs, 2010; Labreuche, 2011) ont proposé de lier l’argumentation et la décision ou les valeurs des individus modélisés. Ces travaux n’ont cependant pas jusqu’ici visé à résoudre les problèmes de l’aide à la décision discutés ici, et n’ont pas proposé de cadre général d’analyse du pouvoir de conviction des arguments auprès des décideurs, comme proposé ici. Certaines propositions existantes dans ce champ peuvent cependant être intégrées à l’approche des préférences argumentées. Labreuche (2011), en particulier, propose de traduire les scores fournis par un modèle d’utilité en arguments (formulés comme des phrases en anglais) en faveur ou en défaveur de certaines alternatives. Ceci peut aisément être intégré au cadre proposé ici et constituer un exemple de modèle de préférences argumentées.

=== Choix social et philosophie politique

À la suite de Rawls, l’économiste et philosophe Sen (2009) a avancé des propositions concernant une théorie de la justice qui contient de nombreux liens avec le sujet d’étude proposé ici. Sen insiste, suivant Adam Smith, sur la nécessité de prendre en compte des arguments aussi divers que possibles lors de débats devant mener à des consensus sur la manière juste d’organiser la société. Ces divers arguments peuvent être apportés par des individus étrangers à la décision à prendre, mais devraient idéalement tous être considérés par les décideurs.

Le cadre proposé permettra d’étudier formellement l’intuition selon laquelle prendre en compte plus d’arguments amène à de meilleures décisions. Il devra ensuite être élargi pour pouvoir également mesurer la diversité des arguments. Il sera intéressant d’étudier empiriquement dans quelle mesure les décideurs s’intéressent à des arguments originaux, et quelles sont les formulations qui les rendent plus percutants, ce point étant lié aux études proposées en section 4.2.2.

Surtout, Sen invite de façon convaincante à abandonner l’objectif de déterminer le système le plus juste, car il lui semble irréaliste. Il propose de se concentrer sur le sous-ensemble de points de vues sur lesquels nous pouvons nous mettre d’accord. Concrètement, Sen a développé un cadre important permettant d’appliquer les analyses classiques du choix social dans des situations où les préférences des votants ne sont pas entièrement déterminées (Sen, 1997). Les liens avec les questions posées ici à propos de la pertinence de la prise en compte de l’incomparabilité sont clairs. Les exemples et argumentations développées par Sen en faveur de la prise en compte de l’incomparabilité, ainsi que ses développements mathématiques en choix social, aideront au développement du cadre proposé ici. Inversement, des découvertes faites dans ce cadre pourront alimenter le débat philosophique et le cadre du choix social formel.

Par ailleurs, Rawls (1999) a proposé le concept du voile d’ignorance auquel nous ferons utilement appel. Pour s’assurer que les personnes considèrent la qualité de l’argumentation et les principes de justice fondamentaux et non pas leur intérêt, il propose d’organiser les débats en situant les protagonistes derrière un voile d’ignorance : ils ignorent quelle sera leur position dans la société future. Dans notre cadre, nous serons intéressés par l’étude des arguments qu’un individu considère comme pertinents lorsqu’il n’a pas d’intérêt, et la comparaison avec ce qu’un individu est prêt à accepter comme argument valable lorsqu’il a des intérêts en jeu. De telles investigations seront intéressantes également pour la philosophe politique.

=== Autres liens

Dans divers champs du savoir, le développement d’indicateurs de qualité est un moyen important de faire progresser la recherche. Ces indicateurs tentent parfois de reproduire de façon automatique, ou formalisée, le jugement humain, considéré comme le meilleur indicateur de qualité disponible. Considérons pour rendre la discussion concrète la traduction automatique. Un problème important pour les chercheurs en analyse de données développant des systèmes de traduction est d’évaluer leur système. On peut demander à un humain de le faire : il juge alors de la qualité de chaque système de traduction. Des chercheurs ont naturellement tenté, pour gagner du temps, de reproduire ce jugement humain à l’aide d’un indicateur automatique (Koehn, 2007, Chapitre 8; Macháček & Bojar, 2013). Cependant, il faut voir que l’objectif final est bien d’évaluer la qualité de la traduction. Si l’humain commet une erreur de jugement lors de son évaluation de qualité, il faudrait éviter de reproduire cette erreur dans le système d’évaluation automatique. Il faudrait donc tenter de reproduire, non pas les préférences de l’humain évaluant le système, mais bien ses préférences argumentées : après prise en compte de certains arguments, l’humain est peut-être prêt à réviser son jugement et considérer que le meilleur système de traduction n’est pas celui qu’il avait intuitivement préféré.

Le cadre proposé introduit également une autre manière de pratiquer les sondages d’opinion. On pourrait effectivement, une fois développés des modèles de préférences argumentées fonctionnant raisonnablement bien (cf. section 4.1), interroger les gens sur leurs préférences réfléchies. Des liens importants sont ici à développer avec la sociologie (Bourdieu, 1973; Meynaud & Duclos, 2007).

Le domaine de la persuasion est également lié aux considérations développées ici : outre des cadres généraux d’analyse des dialogues (Prakken, 2009), des auteurs ont proposé des systèmes dont l’objectif est de convaincre une personne qu’une alternative donnée est la meilleure, à l’aide d’une perspective multicritère (Carenini & Moore, 2006). Mais une différence cruciale nous sépare. Dans ma proposition, un modèle de préférences argumentées, pour être bon, ne doit pas seulement convaincre un humain de l’opportunité d’agir dans un sens donné : il doit également résister aux contre-arguments fournis par des modèles de préférences argumentées concurrents. Ainsi, le développement de ce champ de recherche conduira à des décisions qui résistent mieux aux contre-arguments issus d’horizons variés et ne pose pas les problèmes éthiques posés par le développement de modèles de persuasion. Malgré cette différence, il sera potentiellement intéressant de s’inspirer de tels modèles de persuasion liés à la théorie de l’argumentation.

Un champ disciplinaire récent, l’apprentissage des préférences (preference learning) (Fürnkranz & Hüllermeier, 2010), utilise des techniques d’analyse de données pour modéliser les préférences (au sens classique de l’AMCD). L’existence de grandes bases de données regroupant des informations de préférences (telles que des décisions d’achat) rend ceci possible. L’objectif est ici encore distinct de la proposition de ce projet, puisqu’il ne s’agit pas généralement d’aider le décideur à prendre du recul concernant ses préférences à l’aide d’arguments potentiellement complexes. Typiquement, les techniques développées visent à prédire des décisions d’achat futures en observant les décisions passées, ou visent à analyser quelle suggestion d’achat un site web devrait afficher au visiteur du site afin de maximiser sa probabilité d’achat ou la marge bénéficiaire du vendeur.

Dans cette proposition, les liens avec l’analyse de données sont à développer afin d’étudier comment utiliser de grandes bases de données contenant des arguments pour produire de meilleurs modèles de préférences argumentées. De telles grandes bases de données sont développées actuellement en lien avec le champ de la théorie de l’argumentation (Rahwan, Zablith, & Reed, 2007).

Un dernier champ à mentionner ici est le champ de la révision de croyances (belief revision) (Gärdenfors & Rott, 1993). Il s’agit de modéliser à l’aide d’un langage logique le processus de révision de croyances qu’un agent devrait utiliser lorsqu’il rencontre un nouvel argument. Ce champ de recherche adopte une perspective distincte de celle présentée ici puisqu’il cherche une manière de définir, en principe, la bonne façon de réviser ses croyances, en général sous forme d’axiomes exprimés sous forme logique.

== Décision de groupe

Mon approche propose d’étudier ce qu’une personne donnée considère comme un argument pertinent. La progression des connaissances à ce niveau permettra de faciliter le passage à la difficulté supplémentaire : le développement d’une approche permettant l’agrégation d’opinions multiples.

Dans l’approche de base développée ici, je propose d’étudier l’existence d’incomparabilités irréductibles au sein de la réflexion d’une personne. Un problème similaire se pose lors du passage à de multiples décideurs. Une piste consistera, pour appliquer ces découvertes à la décision de groupe, à suivre la suggestion de Sen : chercher un consensus sur un sous-ensemble de sujets plutôt qu’un consensus complet. À ce niveau en particulier, l’approche proposée communiquera avec les champs du choix social et de l’épistémologie. La compréhension de quels arguments sont pertinents, pour qui, sous quelle forme, aidera à obtenir des consensus robustes et à échapper aux impossibilités liées à l’agrégation d’ensembles de votes comme des rangements de préférence (Arrow, 2012).

== Applications et développement du projet

Par sa généralité, l’étude de préférences argumentées mènera à des applications dans des domaines très divers. Elles permettront d’établir des objectifs intermédiaires concrets, et de nourrir les réflexions théoriques. Après avoir indiqué comment je pense mener ce projet de recherche, je propose deux domaines d’applications en exemple : la suggestion de stratégies de jeux ; et l’explication de preuves mathématiques.

=== Développement du projet

Pour démarrer ce projet, il sera opportun de soumettre à la communauté de l’argumentation formelle, partie de l’intelligence artificielle, une proposition de cadre théorique permettant de comparer des modèles de préférences argumentées, suivant les lignes développées ici. Pour ce faire, des contacts pourront être pris avec des personnes travaillant déjà aux liens entre l’argumentation et l’aide multicritère à la décision : Wassila Ouerdane (2009), ancienne thésarde du LAMSADE avec qui j’ai beaucoup discuté d’argumentation puisqu’elle était maître de conférences à l’École Centrale lorsque j’y effectuais mon doctorat ; Alexis Tsoukiàs au LAMSADE (Moraïtis & Tsoukiàs, 2003), parmi les premiers à avoir insisté sur l’importance du développement des liens entre ces deux champs ; Tony Hunter, expert en théorie de l’argumentation logique (Besnard & Hunter, 2009) qui a déjà proposé des liens avec l’aide multicritère à la décision (Muller & Hunter, 2012) ; Leila Amgoud de l’IRIT, qui s’intéresse également au lien entre ces deux champs (Amgoud & Prade, 2009). Un modèle initial pourrait être proposé à partir du travail de Christophe Labreuche (2011) ainsi qu’indiqué en section 4.2.3. Une collaboration avec Denis Bouyssou (Bouyssou et al., 2006) permettrait de donner une base solide à l’édifice grâce à son expertise dans le développement de systèmes d’axiomes pour des modèles d’AMCD.

Il sera important, en parallèle à l’amélioration du cadre grâce aux commentaires provenant de la communauté de la théorie de l’argumentation, de soumettre la proposition à la critique des philosophes travaillant en épistémologie du désaccord. Les liens esquissés à la section 4.2.2 pourront être développés grâce à des collaborations avec par exemple Christian Skirke et Julian Kiverstein, philosophes qui s’intéressent à ces questions à l’ILLC (où j’effectue actuellement mon post-doctorat), Université d’Amsterdam. Ceci permettra d’intéresser cette communauté et d’obtenir de leur part des propositions d’amélioration du cadre, des modèles d’argumentation, et de manière plus générale de générer des discussions sur les interactions entre la façon dont les gens raisonnent effectivement et les débats tenus dans cette communauté. Les apports de Marc Pirlot, que je connais depuis longtemps, seront également importants puisqu’il a déjà examiné avec Jean-Louis Genard certains parallèles entre l’objectif de l’AMCD et la vision philosophique du rôle de l’argumentation avancée par Habermas (Genard & Pirlot, 2002).

Une prise en compte des critiques issues de ces deux perspectives différentes permettra de mettre en place des modèles d’argumentation et des situations simples pouvant constituer l’objet d’une première étude statistique. Les modèles pourraient être basés par exemple, l’un sur un modèle d’utilité ainsi que proposé par Labreuche (2011) et l’autre sur un modèle de type surclassement (Roy & Bouyssou, 1993). Dans cette hypothèse, l’objet de la première étude viserait à examiner dans quelle mesure les gens modifient leurs préférences lorsqu’ils sont exposés aux arguments proposés par un modèle ou un autre. Un exemple d’hypothèse qui pourrait être testée est : les arguments issus du modèle à base d’utilité, considéré comme classique en théorie de la décision, peuvent dans certains cas être contrés ou utilement complémentés par des arguments issus d’un modèle à base de surclassement. La validation d’une telle hypothèse serait très intéressante pour la théorie de la décision, de même que la mise en évidence de situations d’incomparabilités.

Des situations issues du champ de l’épistémologie du désaccord pourraient constituer l’objet d’une seconde étude. Comme indiqué à la section 4.2.2, certaines de ces situations font intervenir des critères multiples et donc des raisonnements typiquement utilisés dans des modèles d’AMCD, ce qui permettra de faire partager les découvertes et interrogations entre les deux champs disciplinaires. Il serait intéressant de tester la possibilité de faire accepter à un individu deux raisonnements aboutissant à des résultats contradictoires, établissant ainsi l’existence de situations d’incomparabilité, en s’appuyant sur les raisonnements des philosophes. Une telle observation susciterait des discussions intéressantes entre la théorie de la décision, qui dans sa branche classique a jusqu’ici largement négligé cette possibilité, et les philosophes de l’épistémologie du désaccord, habitués à considérer cette hypothèse comme théoriquement plausible mais ne l’ayant pas testé empiriquement dans un cadre formel.

L’étape suivante consistera à utiliser ces modèles de préférences argumentées, ou à en développer des variantes en vue de leur utilisation, dans des contextes de décision publique. Pour ce faire, je pourrai m’appuyer sur l’expertise d’au moins trois laboratoires avec lesquels j’ai des contacts. Outre le LAMSADE déjà cité, le Département Opérations et Systèmes de Décision à Laval, Canada, s’intéresse depuis longtemps au support au développement de politiques publiques grâce à l’AMCD, et Irène Abi-Zeid avec qui je suis en contact depuis plusieurs années y développe un projet visant à aider à l’élaboration de politiques publiques pour l’environnement à Québec à l’aide de la théorie de l’argumentation (Tremblay & Abi-Zeid, 2012). Le GERARD, Group for Research in Decision Analysis au Québec, a également un long historique d’applications de méthodes d’AMCD à la gestion publique (voir Aenishaenslin et al., 2013 pour un exemple récent)

Le développement de politiques publiques présente des défis particuliers, entre autres liés à la forte exigence de légitimité des décisions prises, mais également lié à la nécessité de prendre en compte des valeurs de multiples individus composant la société et au besoin de transparence plus important. Le besoin accru de légitimité provient de l’utilisation de ressources publiques ; du fait que la stratégie adoptée peut avoir des impacts sur des personnes non consultées, et des impacts à divers niveaux (social, économique, culturel) et potentiellement à très long terme ; et du fait que le décideur public a des comptes à rendre à ses administrés (Tsoukiàs, 2013). Le cadre proposé ici offre une possibilité de modéliser les préférences argumentées des citoyens, et une possibilité pour les décideurs de prendre en compte les arguments que les citoyens trouvent pertinents, ceci d’une manière pleinement transparente grâce à la simplicité conceptuelle du cadre. Parce qu’il ne met pas en œuvre une vision particulière et partielle de la rationalité, il peut également offrir une légitimité plus grande aux décisions prises. Les discussions avec le champ de l’épistémologie prises en compte lors de la définition du cadre permettront d’éclairer cet aspect des choses.

Il conviendra sans-doute dans un premier temps d’utiliser l’approche pour éclairer un seul décideur à la fois, l’aide à la décision de groupe introduisant une difficulté supplémentaire. Lorsque cette approche aura porté ses premiers succès en permettant à des décideurs individuels de prendre en compte plus d’arguments qu’ils n’auraient autrement considéré, il conviendra d’étendre l’étude aux situations de décision de groupe, ainsi que discuté à la section 4.3.

Tout en explorant ces aspects, des contacts seront établis avec des industriels visant à développer des applications spécifiques. Ils seront certainement intéressés par le développement de connaissances concernant les produits que des consommateurs souhaitent acquérir de manière réfléchie et sur les arguments jugés pertinents après réflexion. Le partenariat avec l’industrie permettra de financer le développement d’études et l’amélioration des modèles de préférences réfléchies, ainsi que le développement d’un cadre général, théorique et logiciel, permettant leur application à des domaines particuliers.

Outre les applications évidentes qui peuvent être développées dans des secteurs particuliers, par exemple l’aide au choix d’une voiture, d’un lieu de vacances, d’un ordinateur, etc., sont présentées ci-dessous deux applications plus audacieuses illustrant la portée large du cadre proposé ici.

=== Stratégies de jeux

Pour certains jeux tels que les échecs, l’ordinateur est capable de trouver des stratégies efficaces et de battre les humains. Une question importante apparait : comment peut-on utiliser la puissance de calcul et l’intelligence des algorithmes pour aider un humain à mieux jouer ? Explorer cette question obligera à trouver des façons de formuler des conseils qui soient compréhensibles et efficaces. L’exigence de compréhensibilité requiert d’éviter de postuler une capacité de déduction irréaliste chez un humain : il ne suffit pas nécessairement de suggérer à un humain de jouer le meilleur coup que l’ordinateur ait trouvé, si l’on souhaite que l’humain comprenne pourquoi ce coup est bon. L’exigence d’efficacité signifie que le conseil doit être compris et jugé pertinent par l’humain en peu de temps.

Ainsi, lors d’une compétition d’échecs, pourrait se dérouler en parallèle une compétition de modèles de préférences argumentées. Cette compétition parallèle met en concurrence des modèles produisant des arguments concernant ce que le joueur devrait jouer. Les joueurs pourraient, de temps à autres au cours de la compétition, obtenir des conseils de certains de ces systèmes. Certains systèmes produiraient volontairement de mauvais conseils, afin d’obliger les joueurs à réfléchir à l’opportunité de suivre les conseils en fonction de leur contenu argumenté. À l’issue de la compétition, on pourrait déterminer, non seulement le meilleur joueur, mais également quel système a offert la meilleure aide. Pour ce faire, mesurer la différence de performance d’un joueur avec et sans système d’aide pourrait être utile, et dans le cas des échecs pourrait s’appuyer sur la mesure standard de la performance habituelle d’un joueur appelée ELO.

=== Explication de preuves mathématiques

Un autre domaine lié au sujet d’étude proposé est l’explication de preuves. Une tâche importante du chercheur en mathématiques est de parvenir à prouver des théorèmes. Une tâche non moins importante est de parvenir à exposer sa preuve clairement. Ceci est utile non seulement pour publier des articles de recherche mais également à des fins d’enseignement. Il existe souvent de multiples manières de prouver une affirmation, et selon les connaissances de l’audience, certaines stratégies de preuves seront plus ou moins facilement compréhensibles. La meilleure façon de présenter une preuve est également un problème sans solution actuellement. Lamport (1993, 2012) a proposé il y a vingt ans un système de présentation de preuves, mais il n’est pas utilisé actuellement dans les revues mathématiques. Le système proposé ici pourrait être utilisé pour étudier, parmi les multiples présentations possibles d’une preuve, quelles sont les présentations les plus compréhensibles, tout en prenant en compte la subjectivité de l’auditoire. Notons bien que cette proposition ne requiert pas une capacité de construire des systèmes capables de prouver des théorèmes par eux-mêmes : le système utiliserait les preuves déjà établies et sa tâche se limiterait à trouver les meilleurs agencements de ces preuves.

De plus, le cadre proposé ici permet d’envisager les preuves mathématiques comme des argumentations non monotones, et d’étudier leurs liens aux argumentations monotones. Une preuve parfaitement détaillée est bien sûr monotone, au sens de l’argumentation : chaque étape est prouvée de façon non réfutable, définitive, en partant d’un ensemble d’axiomes explicites. Mais en pratique, une preuve parfaitement détaillée serait tellement longue qu’elle serait illisible, et ce qui importe au lecteur humain (chercheur ou étudiant) est l’intuition derrière la preuve. Ainsi, les mathématiciens ne proposent pas de preuves parfaitement détaillées, ils sautent des étapes (ce qui explique également pourquoi de nombreuses preuves sont erronées (Lamport, 1993; Grandi & Endriss, 2009)). L’étude proposée pourrait éclairer les liens entre les preuves parfaitement détaillées, idéales du point de vue de l’exactitude, et les preuves intuitives, idéales du point de vue de la compréhension par un humain.

Ces deux applications sont elles-mêmes très ambitieuses, et leur développement constitue des problèmes de recherche à long terme. Mais elles fournissent également des manières d’avancer progressivement, par le biais de jalons concrets, vers l’objectif plus général de la compréhension du raisonnement, éventuellement non monotone, humain.

En fonction de l’intérêt de l’industrie ou d’autres champs de recherche, il sera bien sûr possible de développer, en parallèle ou en remplacement, des applications dans d’autres domaines mais fonctionnant sur le même principe.

== Conclusion

Nous avons vu que de multiples questions intéressant l’aide à la décision peuvent être liées par le biais de l’argumentation : incomparabilité, thèse de l’unicité, la question de la possibilité d’un consensus complet posée par Sen. Le constructivisme insiste sur le fait que les préférences se développent au cours du processus d’aide à la décision, la psychologie révèle que des modes de raisonnement distincts amènent à des conclusions différentes, et que les façons de poser les questions orientent les conclusions. La nécessité d’une approche prescriptive aidant à prendre des décisions, au-delà de la simple description du comportent humain normal, n’est un mystère pour personne. Mais les difficultés liées à la définition même de l’objet d’étude ont jusqu’ici empêché l’émergence d’une vision unificatrice d’une discipline d’étude scientifique.

Il semble possible de passer outre ces limites par la proposition simple de considérer l’objet d’étude comme étant celui des préférences argumentées : combinant des intérêts descriptifs et normatifs, cette perspective permet de combiner les apports de plusieurs champs disciplinaires. L’approche est descriptive puisqu’elle décrit ce qu’un humain est prêt à accepter comme raisonnable après réflexion, mais est néanmoins appropriée pour l’aide à la décision car elle ne se heurte pas aux limites de la pensée rapide révélées par les psychologues. Elle pourrait constituer un nouveau point de départ, sans pour autant faire table rase puisqu’elle permet l’intégration et l’extension de nombreuses idées développées par l’aide multicritère à la décision, la psychologie, l’épistémologie, la théorie de l’argumentation, le choix social, la philosophe politique.

== Bibliographie
* Aenishaenslin, C., Hongoh, V., Cissé, H. D., Hoen, A. G., Samoura, K., Michel, P., … Bélanger, D. (2013). Multi-criteria decision analysis as an innovative approach to managing zoonoses: results from a study on Lyme disease in Canada. BMC Public Health, 13(1), 897. https://doi.org/10.1186/1471-2458-13-897[doi:10.1186/1471-2458-13-897]
* Allais, M. (1979). The So-called Allais Paradox and Rational Decisions under Uncertainty. In O. H. M. Allais (Éd.), Expected Utility Hypotheses and the Allais Paradox (p. 437–681). D. Reidel, Dordrecht.
* Amgoud, L., & Besnard, P. (2009). Bridging the Gap between Abstract Argumentation Systems and Logic. In L. Godo & A. Pugliese (Éd.), Scalable Uncertainty Management (p. 12‑27). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-642-04388-8_3[doi:10.1007/978-3-642-04388-8_3]
* Amgoud, L., & Prade, H. (2009). Using arguments for making and explaining decisions. Artificial Intelligence, 173(3–4), 413‑436. https://doi.org/10.1016/j.artint.2008.11.006[doi:10.1016/j.artint.2008.11.006]
* Arrow, K. J. (2012). Social choice and individual values. New Haven: Yale University Press.
* Aumann, R. J. (1962). Utility Theory without the Completeness Axiom. Econometrica, 30(3), 445‑462. https://doi.org/10.2307/1909888[doi:10.2307/1909888]
* Baroni, P., & Giacomin, M. (2009). Semantics of Abstract Argument Systems. In G. Simari & I. Rahwan (Éd.), Argumentation in Artificial Intelligence (p. 25‑44). Springer US. https://doi.org/10.1007/978-0-387-98197-0_2[doi:10.1007/978-0-387-98197-0_2]
* Bench-Capon, T., & Atkinson, K. (2009). Abstract Argumentation and Values. In G. Simari & I. Rahwan (Éd.), Argumentation in Artificial Intelligence (p. 45‑64). Springer US. https://doi.org/10.1007/978-0-387-98197-0_3[doi:10.1007/978-0-387-98197-0_3]
* Besnard, P., & Grégoire, É. (2013). Handling Incoming Beliefs. In M. Wang (Éd.), Knowledge Science, Engineering and Management (p. 206‑217). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-642-39787-5_17[doi:10.1007/978-3-642-39787-5_17]
* Besnard, P., & Hunter, A. (2009). Argumentation Based on Classical Logic. In G. Simari & I. Rahwan (Éd.), Argumentation in Artificial Intelligence (p. 133‑152). Springer US. https://doi.org/10.1007/978-0-387-98197-0_7[doi:10.1007/978-0-387-98197-0_7]
* Bourdieu, P. (1973). L’opinion publique n’existe pas. Les temps modernes, 318, 1292‑1309.
* Bous, G., Fortemps, P., Glineur, F., & Pirlot, M. (2010). ACUTA: A novel method for eliciting additive value functions on the basis of holistic preference statements. European Journal of Operational Research, 206(2), 435‑444. https://doi.org/10.1016/j.ejor.2010.03.009[doi:10.1016/j.ejor.2010.03.009]
* Bouyssou, D., Dubois, D., Pirlot, M., & Prade, H. (2006). Concepts et méthodes pour l’aide à la décision, volume 3, analyse multicritère. Hermès.
* Bouyssou, D., & Marchant, T. (2007). An axiomatic approach to noncompensatory sorting methods in MCDM, I: The case of two categories. European Journal of Operational Research, 178(1), 217‑245. https://doi.org/10.1016/j.ejor.2006.01.027[doi:10.1016/j.ejor.2006.01.027]
* Bouyssou, D., & Pirlot, M. (2002). Nontransitive Decomposable Conjoint Measurement. Journal of Mathematical Psychology, 46, 677–703.
* Cailloux, O. (2012). Élicitation indirecte de modèles de tri multicritère (PhD Thesis). École Centrale Paris, Paris.
* Caminada, M., & Pigozzi, G. (2011). On judgment aggregation in abstract argumentation. Autonomous Agents and Multi-Agent Systems, 22(1), 64‑102. https://doi.org/10.1007/s10458-009-9116-7[doi:10.1007/s10458-009-9116-7]
* Carenini, G., & Moore, J. D. (2006). Generating and evaluating evaluative arguments. Artificial Intelligence, 170(11), 925‑952. https://doi.org/10.1016/j.artint.2006.05.003[doi:10.1016/j.artint.2006.05.003]
* Christensen, D. (2007). Epistemology of Disagreement: The Good News. The Philosophical Review, 116(2), 187‑217.
* Christensen, D. (2009). Disagreement as Evidence: The Epistemology of Controversy. Philosophy Compass, 4(5), 756–767. https://doi.org/10.1111/j.1747-9991.2009.00237.x[doi:10.1111/j.1747-9991.2009.00237.x]
* Christensen, D., & Lackey, J. (Éd.). (2013). The epistemology of disagreement: new essays. Oxford: Oxford University Press.
* Damart, S., Dias, L., & Mousseau, V. (2007). Supporting groups in sorting decisions: Methodology and use of a multi-criteria aggregation/disaggregation DSS. Decision Support Systems, 43(4), 1464‑1475.
* Deparis, S., Mousseau, V., Öztürk, M., Pallier, C., & Huron, C. (2012). When conflict induces the expression of incomplete preferences. European Journal of Operational Research, 221(3), 593‑602. https://doi.org/10.1016/j.ejor.2012.03.041[doi:10.1016/j.ejor.2012.03.041]
* Dias, L. C., Mousseau, V., Figueira, J., & Clímaco, J. N. (2002). An aggregation/disaggregation approach to obtain robust conclusions with ELECTRE TRI. European Journal of Operational Research, 138(2), 332‑348.
* Dung, P. M. (1995). On the acceptability of arguments and its fundamental role in nonmonotonic reasoning, logic programming and n-person games. Artificial Intelligence, 77(2), 321 ‑ 357. https://doi.org/10.1016/0004-3702[doi:10.1016/0004-3702](94)00041-X
* Dyer, J. S. (2005). MAUT – Multiattribute Utility Theory. In J. Figueira, S. Greco, & M. Ehrgott (Éd.), Multiple Criteria Decision Analysis: State of the Art Surveys (p. 265‑285). Boston, Dordrecht, London: Springer Verlag. https://doi.org/10.1007/0-387-23081-5_7[doi:10.1007/0-387-23081-5_7]
* Ellsberg, D. (1961). Risk, Ambiguity, and the Savage Axioms. Quarterly Journal of Economics, 75, 643‑669.
* Feldman, R. (2007). Reasonable religious disagreements. In Social Epistemology: Essential Readings (p. 137‑157). New York: Oxford University Press.
* Feldman, R., Warfield, Ted A. (2010). Disagreement. New York: Oxford University Press.
* Fellner, W. (1961). Distortion of Subjective Probabilities as a Reaction to Uncertainty. The Quarterly Journal of Economics, 75(4), 670‑689. https://doi.org/10.2307/1884325[doi:10.2307/1884325]
* Franco, L. A., Montibeller, G., Cochran, J. J., Cox, L. A., Keskinocak, P., Kharoufeh, J. P., & Smith, J. C. (2010). Problem Structuring for Multicriteria Decision Analysis Interventions. In Wiley Encyclopedia of Operations Research and Management Science. John Wiley & Sons, Inc. https://doi.org/10.1002/9780470400531.eorms0683[doi:10.1002/9780470400531.eorms0683]
* Fürnkranz, J., & Hüllermeier, E. (Éd.). (2010). Preference Learning (1st Edition.). Springer. https://doi.org/10.1007/978-3-642-14125-6[doi:10.1007/978-3-642-14125-6]
* Galaabaatar, T., & Karni, E. (2013). Subjective Expected Utility With Incomplete Preferences. Econometrica, 81(1), 255–284. https://doi.org/10.3982/ECTA9621[doi:10.3982/ECTA9621]
* Gärdenfors, P., & Rott, H. (1993). Belief Revision. In D. M. Gabbay, C. J. Hogger, & J. A. Robinson (Éd.), Handbook of logic in artificial intelligence and logic programming, Volume 4: Epistemic and Temporal Reasoning. Oxford University Press.
* Genard, J.-L., & Pirlot, M. (2002). Multi-criteria decision aid in a philosophical perspective. In D. Bouyssou, E. Jacquet-Lagrèze, P. Perny, R. Slowinski, & D. Vanderpooten (Éd.), Aiding Decisions with Multiple Criteria. Essays in Honor of Bernard Roy (Vol. 44, p. 89–117). Springer. https://doi.org/10.1007/978-1-4615-0843-4_5[doi:10.1007/978-1-4615-0843-4_5]
* Gilbert, D. T. (2006). Stumbling on happiness. New York: A.A. Knopf.
* Grandi, U., & Endriss, U. (2009). First-Order Logic Formalisation of Arrow’s Theorem. In X. He, J. Horty, & E. Pacuit (Éd.), Logic, Rationality, and Interaction (p. 133‑146). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-642-04893-7_11[doi:10.1007/978-3-642-04893-7_11]
* Greco, S., Kadziński, M., Mousseau, V., & Słowiński, R. (2012). Robust ordinal regression for multiple criteria group decision: UTAGMS-GROUP and UTADISGMS-GROUP. Decision Support Systems, 52(3), 549‑561. https://doi.org/10.1016/j.dss.2011.10.005[doi:10.1016/j.dss.2011.10.005]
* Greco, S., Mousseau, V., & Słowiński, R. (2010). Multiple criteria sorting with a set of additive value functions. European Journal of Operational Research, 207(3), 1455‑1470. https://doi.org/10.1016/j.ejor.2010.05.021[doi:10.1016/j.ejor.2010.05.021]
* Hill, B. (2012). Confidence in Preferences. Social Choice and Welfare, 39(2), 273‑302.
* Kadziński, M., Greco, S., & Słowiński, R. (2012). Selection of a representative value function in robust multiple criteria ranking and choice. European Journal of Operational Research, 217(3), 541‑553. https://doi.org/10.1016/j.ejor.2011.09.032[doi:10.1016/j.ejor.2011.09.032]
* Kahneman, D. (2013). Thinking, fast and slow. New York: Farrar, Straus and Giroux.
* Keeney, R. L., & Raiffa, H. (1993). Decisions with multiple objectives: preferences and value tradeoffs. Cambridge University Press.
* Kelly, T. (2010). Peer disagreement and higher order evidence. In Social Epistemology: Essential Readings (p. 183–217).
* Koehn, P. (2007). Statistical machine translation. Cambridge University Press.
* Labreuche, C. (2011). A general framework for explaining the results of a multi-attribute preference model. Artificial Intelligence, 175(7–8), 1410 ‑ 1448. https://doi.org/10.1016/j.artint.2010.11.008[doi:10.1016/j.artint.2010.11.008]
* Lamport, L. (1993). How to write a proof. In K. Uhlenbeck (Éd.), Global Analysis in Modern Mathematics (p. 311–321). Houston, Texas: Publish or Perish.
* Lamport, L. (2012). How to write a 21st century proof. Journal of Fixed Point Theory and Applications, 11(1), 43‑63. https://doi.org/10.1007/s11784-012-0071-6[doi:10.1007/s11784-012-0071-6]
* Lang, J., Pigozzi, G., Slavkovik, M., & van der Torre, L. (2011). Judgment Aggregation Rules Based on Minimization. In Proceedings of the 13th Conference on Theoretical Aspects of Rationality and Knowledge (p. 238–246). New York, NY, USA: ACM. https://doi.org/10.1145/2000378.2000407[doi:10.1145/2000378.2000407]
* Lichtenstein, S., & Slovic, P. (Éd.). (2006). The Construction of Preference. Cambridge University Press.
* Macháček, M., & Bojar, O. (2013). Results of the WMT13 Metrics Shared Task. In Proceedings of the Eighth Workshop on Statistical Machine Translation (p. 45–51). Sofia, Bulgaria: Association for Computational Linguistics. http://www.statmt.org/wmt13/papers.html
* Marchant, T., & Pirlot, M. (1999). Modern decisive wives don’t wear corsets. Journal of Multi-Criteria Decision Analysis, 8(4), 237–238. https://doi.org/10.1002/[doi:10.1002/](SICI)1099-1360(199907)8:4<237::AID-MCDA250>3.0.CO;2-Z
* Mayag, B., Cailloux, O., & Mousseau, V. (2011). MCDA tools and Risk Analysis: the Decision Deck Project. In C. Bérenguer, A. Grall, & C. Guedes Soares (Éd.), Advances in Safety, Reliability and Risk Management (p. 2324‑2330). Taylor and Francis Group, London.
* Meynaud, H.-Y., & Duclos, D. (2007). Les sondages d’opinion. Paris: La Découverte.
* Mingers, J., & Rosenhead, J. (2001). Rational analysis for a problematic world revisited: problem structuring methods for complexity, uncertainty and conflict. Chichester; New York: Wiley.
* Mongin, P. (2006). Value Judgments and Value Neutrality in Economics. Economica, (73), 257‑286.
* Moraïtis, P., & Tsoukiàs, A. (2003). Decision Aiding and Argumentation. In Proceedings of the 1st European Workshop on Multi-Agent Systems (EUMAS’03).
* Mousseau, V., & Słowiński, R. (1998). Inferring an ELECTRE TRI model from assignment examples. Journal of Global Optimization, 12(2), 157‑174.
* Muller, J., & Hunter, A. (2012). An Argumentation-Based Approach for Decision Making. In 2012 IEEE 24th International Conference on Tools with Artificial Intelligence (ICTAI) (Vol. 1, p. 564‑571). https://doi.org/10.1109/ICTAI.2012.82[doi:10.1109/ICTAI.2012.82]
* Nozick, R. (1969). Newcomb’s Problem and Two Principles of Choice. In N. Rescher (Éd.), Essays in Honor of Carl G. Hempel (p. 114‑146). Springer Netherlands. https://doi.org/10.1007/978-94-017-1466-2_7[doi:10.1007/978-94-017-1466-2_7]
* Ouerdane, W. (2009). Multiple Criteria Decision Aiding : a Dialectical Perspective. University of Paris Dauphine, France.
* Ouerdane, W., Maudet, N., & Tsoukiàs, A. (2010). Argumentation Theory and Decision Aiding. In M. Ehrgott, J. R. Figueira, & S. Greco (Éd.), Trends in Multiple Criteria Decision Analysis (Vol. 142, p. 177‑208). Springer US. https://doi.org/10.1007/978-1-4419-5904-1_7[doi:10.1007/978-1-4419-5904-1_7]
* Pollock, J. L. (1986). Contemporary theories of knowledge. Totowa, N.J.: Rowman & Littlefield.
* Pollock, J. L. (2006). Thinking about Acting: Logical Foundations for Rational Decision Making. Oxford University Press.
* Prakken, H. (2009). Models of Persuasion Dialogue. In G. Simari & I. Rahwan (Éd.), Argumentation in Artificial Intelligence (p. 281‑300). Springer US. https://doi.org/10.1007/978-0-387-98197-0_14[doi:10.1007/978-0-387-98197-0_14]
* Rahwan, I., Zablith, F., & Reed, C. (2007). Laying the foundations for a World Wide Argument Web. Artificial Intelligence, 171(10–15), 897‑921. https://doi.org/10.1016/j.artint.2007.04.015[doi:10.1016/j.artint.2007.04.015]
* Rawls, J. (1999). A theory of justice (Revised Edition.). Cambridge, Massachusetts: Belknap Press.
* Rosen, G. (2001). Nominalism, Naturalism, Epistemic Relativism. Noûs, 35, 69‑91.
* Roy, B. (1985). Méthodologie multicritère d’aide à la décision. Paris: Economica.
* Roy, B., & Bouyssou, D. (1993). Aide Multicritère à la Décision : Méthodes et Cas. Paris: Economica. http://www.lamsade.dauphine.fr/~bouyssou/pub.html
* Roy, B., & Vincke, P. (1998). The case of the vanishing optimum revisited again. Journal of Multi-Criteria Decision Analysis, 7, 351.
* Schärlig, A. (1996). The case of the vanishing optimum. Journal of Multi-Criteria Decision Analysis, 5, 160‑164.
* Sen, A. (1997). Maximization and the Act of Choice. Econometrica, 65(4), 745‑779. https://doi.org/10.2307/2171939[doi:10.2307/2171939]
* Sen, A. (2009). The Idea of Justice. Cambridge, Massachusetts: Belknap Press.
* Sigl, J. C., & Chamoun, N. G. (1994). An introduction to bispectral analysis for the electroencephalogram. Journal of Clinical Monitoring, 10(6), 392‑404.
* Slovic, P., & Tversky, A. (1974). Who accepts Savage’s axiom? Behavioral Science, 19, 368–373.
* Tremblay, J., & Abi-Zeid, I. (2012). Value-based argumentation and policy decision analysis - Methodology and a case study of an environmental project in Quebec. Submitted to Annals of OR on Policy Analytics.
* Tsoukiàs, A. (2013). L’Aide à la Décision pour la Conception, la mise en œuvre et l’évaluation des politiques publiques (Document du LAMSADE d’appui au défi CNRS).
* Tversky, A., Sattath, S., & Slovic, P. (1988). Contingent weighting in judgment and choice. Psychological Review, 95(3), 371‑384. https://doi.org/10.1037/0033-295X.95.3.371[doi:10.1037/0033-295X.95.3.371]
* Van der Meer, J. (2012). Multi-criteria decision model inference and application in information security risk classification (Master Thesis). Erasmus University Rotterdam, Rotterdam, Netherlands. http://thesis.eur.nl/pub/12227/
* Von Neumann, J., & Morgenstern, O. (2007). Theory of Games and Economic Behavior (60th Anniversary Commemorative Edition). Princeton University Press.
* White, R. (2005). Epistemic Permissiveness. Philosophical Perspectives, 19(1), 445–459. https://doi.org/10.1111/j.1520-8583.2005.00069.x[doi:10.1111/j.1520-8583.2005.00069.x]
* Williamson, T. (2008). The Philosophy of Philosophy. John Wiley & Sons.
* Zheng, J., Cailloux, O., & Mousseau, V. (2011). Constrained Multicriteria Sorting Method Applied to Portfolio Selection. In R. I. Brafman, F. S. Roberts, & A. Tsoukiàs (Éd.), Proceedings of the 2nd International Conference on Algorithmic Decision Theory (Vol. 6992, p. 331‑343). Springer. https://doi.org/10.1007/978-3-642-24873-3_25[doi:10.1007/978-3-642-24873-3_25]
* Zionts, S. (1997). The case of the vanishing optimum revisited. Journal of Multi-Criteria Decision Analysis, 6, 247.

